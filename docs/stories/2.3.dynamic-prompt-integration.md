# Story 2.3: Dynamic Prompt Integration

## Status
Draft

## Story
**As a** Product Owner,
**I want** the extension to use my custom prompts instead of hardcoded ones when generating AI feedback,
**so that** I receive more targeted and relevant story improvement suggestions based on my specific requirements.

## Acceptance Criteria
1. Modify background script API calls to use custom prompts instead of hardcoded ones
2. Implement automatic fallback to default prompts when custom prompts fail or are invalid
3. Support dynamic variable substitution in prompt templates (story content, user context, etc.)
4. Ensure custom prompt integration works with all supported AI providers (OpenAI, Anthropic, Custom)
5. Maintain existing API error handling and timeout behavior with custom prompts

## Tasks / Subtasks
- [ ] Refactor background script prompt handling (AC: 1)
  - [ ] Remove hardcoded prompt strings from sendToLLM function
  - [ ] Implement getEffectivePrompt(provider) function with storage retrieval
  - [ ] Update API payload construction to use dynamic prompts
  - [ ] Ensure prompt loading doesn't block API request performance
- [ ] Implement fallback mechanism (AC: 2)
  - [ ] Add prompt validation before API calls
  - [ ] Create fallback logic when custom prompts are invalid/missing
  - [ ] Implement default prompt repository as embedded constants
  - [ ] Add logging for fallback scenarios for debugging
- [ ] Build variable substitution system (AC: 3)
  - [ ] Create template engine for variable replacement ({{variableName}})
  - [ ] Define standard variables: {{storyContent}}, {{timestamp}}, {{provider}}
  - [ ] Add user-defined variable support from feedback context
  - [ ] Implement safe substitution with error handling for missing variables
- [ ] Ensure cross-provider compatibility (AC: 4)
  - [ ] Update OpenAI API integration with custom prompts
  - [ ] Update Anthropic API integration with custom prompts  
  - [ ] Update Custom endpoint integration with custom prompts
  - [ ] Test prompt formatting compatibility across different API schemas
- [ ] Maintain existing error handling (AC: 5)
  - [ ] Preserve existing timeout behavior with custom prompts
  - [ ] Maintain API error response handling and user feedback
  - [ ] Ensure loading indicators work with dynamic prompt processing
  - [ ] Add custom prompt-specific error scenarios and handling
- [ ] Update feedback display integration (AC: 1, 2)
  - [ ] Ensure feedback window receives context about which prompt was used
  - [ ] Add prompt debugging information for development/troubleshooting
  - [ ] Update error messages to include prompt-related issues
  - [ ] Maintain existing clipboard and export functionality
- [ ] Add comprehensive testing (AC: 1-5)
  - [ ] Unit tests for dynamic prompt loading and substitution
  - [ ] Unit tests for fallback mechanism
  - [ ] Unit tests for cross-provider compatibility
  - [ ] Integration tests for complete feedback flow with custom prompts
  - [ ] Manual testing with real API responses using custom prompts

## Dev Notes

### Previous Story Insights
[Source: docs/stories/2.2.prompt-storage-retrieval.md#dev-notes]
- Storage schema extension implemented with customPrompts object per provider
- OptionsManager enhanced with prompt storage/retrieval methods
- Default prompt templates defined as fallback values
- Background script integration points identified for prompt injection

### Technology Stack
[Source: docs/technical/technology-stack.md]
- **Language**: JavaScript (vanilla, no frameworks)
- **API Communication**: REST API with dynamic prompt templates
- **Template Engine**: Custom variable substitution system
- **Error Handling**: Extends existing background script error handling

### Current Background Script API Integration
[Source: docs/stories/1.2.provide-feedback.md#dev-notes + background/background.js analysis]
Current sendToLLM function structure:
- Handles provider-specific API endpoints (OpenAI, Anthropic, Custom)
- Constructs API payloads with hardcoded prompts
- Implements timeout handling and error responses
- Returns formatted response to feedback window

### API Provider Prompt Formats
[Source: Background script analysis]
Each provider has different prompt format requirements:

**OpenAI Format:**
```javascript
{
  messages: [
    { role: "system", content: customPrompt },
    { role: "user", content: storyContent }
  ]
}
```

**Anthropic Format:**
```javascript
{
  messages: [
    { role: "human", content: customPrompt + "\n\n" + storyContent }
  ]
}
```

**Custom Format:**
```javascript
{
  prompt: customPrompt, // Variable substitution applied
  content: storyContent
}
```

### Variable Substitution System
[Source: Analysis and requirements]
Standard template variables to support:
- `{{storyContent}}` - The extracted user story text
- `{{timestamp}}` - Current timestamp for context
- `{{provider}}` - Current AI provider name
- `{{feedbackType}}` - Type of feedback being requested
- `{{userContext}}` - Additional user-provided context (future)

Template engine needs to handle:
- Missing variable detection and error handling
- Recursive substitution prevention
- HTML/special character escaping for API safety

### Fallback Mechanism Design
[Source: Requirements analysis]
Fallback priority order:
1. User's custom prompt for current provider
2. Default prompt for current provider
3. Generic default prompt (provider-agnostic)
4. Emergency hardcoded prompt (last resort)

### Integration with Existing Error Handling
[Source: docs/stories/1.2.provide-feedback.md#dev-notes]
Current error handling includes:
- API authentication errors
- Network timeout scenarios
- API quota/rate limiting
- Invalid response format handling

Must extend with:
- Custom prompt validation errors
- Template substitution failures
- Fallback mechanism status
- Prompt-related debugging information

### Performance Considerations
[Source: docs/fullstack-architecture.md#component-interactions]
- Prompt loading should not introduce significant delay
- Template substitution must be efficient for large story content
- Caching of processed prompts for repeated use
- Async loading pattern to maintain UI responsiveness

### Debugging and Troubleshooting
[Source: Previous implementation patterns]
Add debug information for:
- Which prompt was actually used (custom vs fallback)
- Template variable substitution results
- Prompt validation failures
- Provider-specific prompt formatting

### Project Structure Notes
Files to modify:
- `/background/background.js` - Main prompt integration and API calls
- `/feedback/feedback.js` - Display prompt context and debug info
- `/tests/background.test.js` - Extend tests for prompt integration
- New test files for template engine and fallback mechanism

### Testing Strategy
[Source: Previous story testing patterns]
- **Unit Testing**: Template substitution, fallback logic, provider compatibility
- **Integration Testing**: Complete flow from prompt customization to API response
- **Manual Testing**: Real API calls with various custom prompt configurations
- **Error Scenario Testing**: Invalid prompts, missing variables, API failures

### Backward Compatibility
[Source: Epic requirements]
- Must work with users who haven't customized prompts (use defaults)
- Existing API integrations must continue to function normally
- No breaking changes to existing extension functionality
- Graceful handling of storage schema migration

## Change Log
| Date       | Version | Description                      | Author |
|------------|---------|----------------------------------|--------|
| 2025-08-01 | 1.0     | Initial story draft              | BMad   |

## Dev Agent Record

### Agent Model Used
*To be populated during implementation*

### Debug Log References
*To be populated during implementation*

### Completion Notes List
*To be populated during implementation*

### File List
*To be populated during implementation*

## QA Results
*Results from QA Agent review will be populated here after story completion*